This project will (eventually) attempt to explore the following concepts:
- **Shared Perception-Action Representations**: Features that simultaneously represent perceptual information and action possibilities
- **Ideomotor Learning**: How robots can learn action-effect associations through experience
- **Active Perception**: How robots can use sensorimotor interactions to actively explore and learn about their environment
- **Task driven modulation**: How current goals influence event coding
- **Reward driven modulation**: How rewards and internal drives can modulate event coding
- **Semantic Grounding**: How can meaning be generated through these sensorimotor associations?
- **Attention driven modulation**: How can attention mechanisms influence event coding?
- **Hierarchical Feature Development**: How can robots learn complex features through hierarchical representations?
- **Multi-modal Integration**: How can robots integrate multiple sensor modalities (e.g., vision, LIDAR) into a unified coding framework?
- **Metacognitive Monitoring**: How can robots monitor their own cognitive processes and adapt their behavior accordingly?

---